{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time\n",
    "import pytz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = '#SuperBowl'\n",
    "hashtag_dict = {'#GoHawks' : 'tweets_#gohawks.txt',\n",
    "                '#GoPatriots' : 'tweets_#gopatriots.txt',\n",
    "                '#NFL' : 'tweets_#nfl.txt',\n",
    "                '#Patriots' : 'tweets_#patriots.txt',\n",
    "                '#SB49' : 'tweets_#sb49.txt',\n",
    "                '#SuperBowl' : 'tweets_#superbowl.txt'}\n",
    "\n",
    "input_file = open('./tweet_data/' + hashtag_dict[hashtag])\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "total_list = []\n",
    "i = 0\n",
    "for line in input_file:\n",
    "    curr_list = []\n",
    "    curr_data = json.loads(line)\n",
    "    citation_date = curr_data['citation_date']\n",
    "    \n",
    "    location = curr_data['tweet']['user']['location']\n",
    "    text = curr_data['highlight']\n",
    "    curr_list.append(text)\n",
    "    curr_list.append(location)\n",
    "    if citation_date > end_time:\n",
    "        total_list.append(curr_list)\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               MALAYSIA\n",
      "1                                   Ohio\n",
      "2                                       \n",
      "3            #NinerEmpire  #GoLobos  #23\n",
      "4                             Dallas, TX\n",
      "5                                       \n",
      "6                LA ~ Chicago ~ NYC ~ FL\n",
      "7                                       \n",
      "8                             Boston, MA\n",
      "9                                       \n",
      "10        Total Divas on E! & RAW on USA\n",
      "11                                      \n",
      "12                               Arizona\n",
      "13                    Dare you to watch \n",
      "14                                      \n",
      "15                                      \n",
      "16                   Piro, Osa Peninsula\n",
      "17                 Copenhagen & New York\n",
      "18                                Boston\n",
      "19                                      \n",
      "20                             Vancouver\n",
      "21                            Malibu, CA\n",
      "22              United States of America\n",
      "23                     Herndon, Virginia\n",
      "24                     Herndon, Virginia\n",
      "25                         Rochester, NY\n",
      "26              Virginia Beach, VA 23464\n",
      "27                           Houston, TX\n",
      "28              Location: On your wrist \n",
      "29                       Los Angeles, CA\n",
      "                       ...              \n",
      "107257                            LA/NYC\n",
      "107258                      Philadelphia\n",
      "107259                                  \n",
      "107260                            Berlin\n",
      "107261                                  \n",
      "107262                             Tampa\n",
      "107263                                  \n",
      "107264                       /dev/random\n",
      "107265                                  \n",
      "107266                                  \n",
      "107267                                  \n",
      "107268                                  \n",
      "107269                            Online\n",
      "107270                                  \n",
      "107271                                  \n",
      "107272                                  \n",
      "107273                      Chicopee, MA\n",
      "107274                       Acworth, GA\n",
      "107275                        California\n",
      "107276                     Pensacola, FL\n",
      "107277                        New Jersey\n",
      "107278                                  \n",
      "107279                    Somerville, MA\n",
      "107280                      New York, NY\n",
      "107281                       boston XLIX\n",
      "107282                                  \n",
      "107283                                  \n",
      "107284                           Arizona\n",
      "107285                   Phoenix Arizona\n",
      "107286                                  \n",
      "Name: location, Length: 107287, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Data = pd.DataFrame(total_list,columns=['text','location'])\n",
    "Data = Data.reset_index(drop=True)\n",
    "print(Data[:]['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "text_w = []\n",
    "location_w = []\n",
    "text_m = []\n",
    "location_m = []\n",
    "\n",
    "list_w = ['Washington', 'WA', 'washington', 'WASHINGTON']\n",
    "list_m = ['Massachusetts', 'massachusetts', 'MA', 'MASSACHUSETTS' ]\n",
    "list_dc = ['DC', 'D.C.', 'dc', 'd.c.']\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for index, row in Data.iterrows():\n",
    "    list_row1 = re.split('; |, ',row[1])\n",
    "    if any(x in list_row1 for x in list_w) and not any(y in list_row1 for y in list_dc):\n",
    "        text = row[0].split('http')\n",
    "        temp = re.sub('\\s#', ' ', text[0], flags=re.IGNORECASE)\n",
    "        testimonial = TextBlob(temp)\n",
    "        \n",
    "        text_w.append(testimonial.sentiment.polarity)\n",
    "        location_w.append(0)\n",
    "        i += 1\n",
    "    elif any(x in list_row1 for x in list_m):\n",
    "        text = row[0].split('http')\n",
    "        temp = re.sub('\\s#', ' ', text[0], flags=re.IGNORECASE)\n",
    "        testimonial = TextBlob(temp)\n",
    "        if testimonial.sentiment.polarity < -0.2: \n",
    "            text_m.append(testimonial.sentiment.polarity)\n",
    "            location_m.append(1)\n",
    "            j += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from textblob import TextBlob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def plot(test_target, predicted):\n",
    "    # Compute fpr, tpr, thresholds and roc auc\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_target, predicted)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "def performance(clf):\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "    x = text_w + text_m\n",
    "    import numpy as np\n",
    "    x = np.asarray(x)\n",
    "    x = np.repeat(x,2)\n",
    "    x = np.reshape(x,(-1,2))\n",
    "    scores = cross_validate(clf, x, location_w + location_m, scoring=scoring, cv=5, return_train_score=False)\n",
    "    mean = scores['test_accuracy'].mean()\n",
    "    recall = scores['test_recall_macro'].mean()\n",
    "    precision = scores['test_precision_macro'].mean()\n",
    "\n",
    "\n",
    "    print('accuracy:%s'%mean)\n",
    "    \n",
    "    print('recall:%s'%recall)\n",
    "    print('precision:%s'%precision)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9018841800551611\n",
      "recall:0.9320803842450701\n",
      "precision:0.8293157977598848\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(probability=True, C = 1, random_state=42)\n",
    "performance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
